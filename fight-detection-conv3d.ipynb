{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":193145354,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:00:14.742052Z","iopub.execute_input":"2024-08-20T13:00:14.742925Z","iopub.status.idle":"2024-08-20T13:00:28.582486Z","shell.execute_reply.started":"2024-08-20T13:00:14.742889Z","shell.execute_reply":"2024-08-20T13:00:28.581374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Imports -------------------------------------------------------------------------------------------------------\nimport torch\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom torchsummary import summary\n\nimport os\nimport shutil\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nimport copy\n#------------------------------------------------------------------------------------------------------------------","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-20T13:00:31.491474Z","iopub.execute_input":"2024-08-20T13:00:31.492398Z","iopub.status.idle":"2024-08-20T13:00:31.738679Z","shell.execute_reply.started":"2024-08-20T13:00:31.492360Z","shell.execute_reply":"2024-08-20T13:00:31.737924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Initialize ---------------------------------------------------------------------------------------------------\nds_zip_path = '/kaggle/input/ucf-get-fights-and-normals/data.zip'\nds_unzip_path = '/kaggle/working/data'\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'device: {DEVICE}')\n\nBATCH_SIZE = 8\nNUM_EPOCHS = 10\n\nNUM_FRAMES = 16\nFRAME_W = 64\nFRAME_H = 64\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:00:37.904451Z","iopub.execute_input":"2024-08-20T13:00:37.905417Z","iopub.status.idle":"2024-08-20T13:00:37.969819Z","shell.execute_reply.started":"2024-08-20T13:00:37.905373Z","shell.execute_reply":"2024-08-20T13:00:37.968788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- unzip data ---------------------------------------------------------------------------------------------------\nshutil.unpack_archive(ds_zip_path, ds_unzip_path, 'zip')\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:00:40.824982Z","iopub.execute_input":"2024-08-20T13:00:40.825891Z","iopub.status.idle":"2024-08-20T13:01:20.904929Z","shell.execute_reply.started":"2024-08-20T13:00:40.825854Z","shell.execute_reply":"2024-08-20T13:01:20.904049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to count number of samples is ds --------------------------------------------------------------------\ndef count_samples(data_dir):\n    counts = {}\n    \n    for subset in ['train', 'val', 'test']:\n        subset_path = os.path.join(data_dir, subset)\n        counts[subset] = {}\n        \n        for category in ['Normal', 'Fighting']:\n            category_path = os.path.join(subset_path, category)\n            num_samples = len(os.listdir(category_path))\n            counts[subset][category] = num_samples\n    \n    return counts\n#------------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:03:24.905183Z","iopub.execute_input":"2024-08-20T13:03:24.905846Z","iopub.status.idle":"2024-08-20T13:03:24.912320Z","shell.execute_reply.started":"2024-08-20T13:03:24.905816Z","shell.execute_reply":"2024-08-20T13:03:24.911223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Dataset size -------------------------------------------------------------------------------------------------\nsample_counts = count_samples(ds_unzip_path)\n\n# Print the sample counts\nfor subset, categories in sample_counts.items():\n    print(f\"{subset} set:\")\n    for category, count in categories.items():\n        print(f\"  {category}: {count} samples\")\n#------------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:03:27.013182Z","iopub.execute_input":"2024-08-20T13:03:27.013557Z","iopub.status.idle":"2024-08-20T13:03:27.020398Z","shell.execute_reply.started":"2024-08-20T13:03:27.013515Z","shell.execute_reply":"2024-08-20T13:03:27.019442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #-- Check Number of Frames and Resolution of Videos -------------------------------------------------------------\n# for root, dirs, files in os.walk(ds_unzip_path):\n    \n#     for filename in files:\n#         file_path = os.path.join(root, filename)   \n        \n#         if file_path.endswith(('.mp4')):          \n#             cap = cv2.VideoCapture(file_path)        \n\n#             width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n#             height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n#             num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n\n#             print(f\"Video: {filename} | number of frames: {num_frames} - Resolution: {width} x {height}\")\n\n#             # Release the video capture object\n#             cap.release()\n# #------------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Convert Video to Numpy Array ---------------------------------------------------------------------\ndef load_video_frames(video_path, num_frames=NUM_FRAMES, resize=(FRAME_W, FRAME_H)):\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    for i in range(num_frames):\n        frame_id = int(i * total_frames / num_frames)\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n        ret, frame = cap.read()\n        if ret:\n            frame = cv2.resize(frame, resize)\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  \n            frames.append(frame)\n        else:\n            break\n    \n    cap.release()\n\n    while len(frames) < num_frames:\n        frames.append(np.zeros((resize[0], resize[1], 3)))\n\n    return np.array(frames)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:03:47.782740Z","iopub.execute_input":"2024-08-20T13:03:47.783110Z","iopub.status.idle":"2024-08-20T13:03:47.792031Z","shell.execute_reply.started":"2024-08-20T13:03:47.783080Z","shell.execute_reply":"2024-08-20T13:03:47.790974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Dataset class for loading the videos ------------------------------------------------------------------------\nclass VideoDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = ['Fighting', 'Normal'] \n        self.samples = []\n        for class_idx, class_name in enumerate(self.classes):\n            class_path = os.path.join(self.root_dir, class_name)\n            for video_file in os.listdir(class_path):\n                if video_file.endswith(('.mp4')):  \n                    self.samples.append((os.path.join(class_path, video_file), class_idx))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        video_path, class_idx = self.samples[idx]\n        video_frames = load_video_frames(video_path) \n        \n        video_frames = torch.from_numpy(video_frames).float()  \n        video_frames = video_frames.permute(3, 0, 1, 2)  #-- Channels first\n        \n        #-- Convert frames from uint8 to float32 and scale to [0, 1]\n        video_frames = video_frames.float() / 255.0\n        \n        if self.transform:\n            video_frames = self.transform(video_frames)\n        return video_frames, class_idx\n\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:03:51.146672Z","iopub.execute_input":"2024-08-20T13:03:51.147356Z","iopub.status.idle":"2024-08-20T13:03:51.156054Z","shell.execute_reply.started":"2024-08-20T13:03:51.147325Z","shell.execute_reply":"2024-08-20T13:03:51.155117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Load Data ----------------------------------------------------------------------------------------------------\n#-- Set the paths to dataset --\ntrain_dir = '/kaggle/working/data/train'\nval_dir = '/kaggle/working/data/val'\ntest_dir = '/kaggle/working/data/test'\n\n\n#-- Create datasets for train, val, and test --\ntrain_dataset = VideoDataset(root_dir=train_dir)\nval_dataset = VideoDataset(root_dir=val_dir)\ntest_dataset = VideoDataset(root_dir=test_dir)\n\n#-- Create DataLoaders --\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:03:53.915021Z","iopub.execute_input":"2024-08-20T13:03:53.915666Z","iopub.status.idle":"2024-08-20T13:03:53.923811Z","shell.execute_reply.started":"2024-08-20T13:03:53.915630Z","shell.execute_reply":"2024-08-20T13:03:53.922802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #-- Check Data Loaders -------------------------------------------------------------------------------------------\n# for i, (videos, labels) in enumerate(train_loader):\n#         print(videos.shape, labels.shape)\n#         break\n# #-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T08:09:36.842045Z","iopub.execute_input":"2024-08-20T08:09:36.842475Z","iopub.status.idle":"2024-08-20T08:09:36.850448Z","shell.execute_reply.started":"2024-08-20T08:09:36.842436Z","shell.execute_reply":"2024-08-20T08:09:36.849504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- 3DCNN based Model for Fight Detection ------------------------------------------------------------------------\nclass FightNet(nn.Module):\n    def __init__(self, num_classes=2):\n        super(FightNet, self).__init__()\n        \n        self.conv1 = nn.Conv3d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv3d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n        \n        self.fc1 = nn.Linear(256 * 2 * 8 * 8, 512) \n        self.fc2 = nn.Linear(512, num_classes)\n        self.pool = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n\n    def forward(self, x):        \n#         print('0----' , x.shape)\n        x = self.pool(F.relu(self.conv1(x)))      \n#         print('1----' , x.shape)\n        x = self.pool(F.relu(self.conv2(x)))   \n#         print('2----' , x.shape)\n        x = self.pool(F.relu(self.conv3(x)))\n#         print('3----' , x.shape)\n        \n        x = x.view(x.size(0), -1)  #-- Flatten       \n#         print('4----' , x.shape)\n        x = F.relu(self.fc1(x))        \n        x = self.fc2(x)        \n        return x\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:04:12.857006Z","iopub.execute_input":"2024-08-20T13:04:12.857402Z","iopub.status.idle":"2024-08-20T13:04:12.867660Z","shell.execute_reply.started":"2024-08-20T13:04:12.857370Z","shell.execute_reply":"2024-08-20T13:04:12.866671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Train Model --------------------------------------------------------------------------------------\ndef train(model, loader, optimizer, criterion):\n    model.train()\n    \n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for videos, labels in loader:\n        \n        videos, labels = videos.to(DEVICE), labels.to(DEVICE)\n\n        optimizer.zero_grad()\n        outputs = model(videos)       \n        \n        \n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n\n    loss = running_loss / len(loader)\n    accuracy = correct / total\n    return loss , accuracy\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:04:16.465356Z","iopub.execute_input":"2024-08-20T13:04:16.466059Z","iopub.status.idle":"2024-08-20T13:04:16.473165Z","shell.execute_reply.started":"2024-08-20T13:04:16.466026Z","shell.execute_reply":"2024-08-20T13:04:16.472216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #-- Function to Evaluate Model -----------------------------------------------------------------------------------\ndef evaluate(model, loader, criterion):\n    model.eval()\n    \n    correct = 0\n    total = 0\n    running_loss = 0.0\n\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    loss = running_loss / len(loader)\n    acc = correct / total\n    return loss , acc\n# #-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:04:18.835276Z","iopub.execute_input":"2024-08-20T13:04:18.835670Z","iopub.status.idle":"2024-08-20T13:04:18.842963Z","shell.execute_reply.started":"2024-08-20T13:04:18.835640Z","shell.execute_reply":"2024-08-20T13:04:18.841988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Create and Initialize Model and its Params -------------------------------------------------------------------\nmodel = FightNet(num_classes=2).to(DEVICE)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:04:22.646017Z","iopub.execute_input":"2024-08-20T13:04:22.646920Z","iopub.status.idle":"2024-08-20T13:04:23.120978Z","shell.execute_reply.started":"2024-08-20T13:04:22.646873Z","shell.execute_reply":"2024-08-20T13:04:23.119870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Display the model summary ------------------------------------------------------------------------------------\nsummary(model, input_size=(3,16,64,64))\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:07:44.125450Z","iopub.execute_input":"2024-08-20T13:07:44.126367Z","iopub.status.idle":"2024-08-20T13:07:44.957890Z","shell.execute_reply.started":"2024-08-20T13:07:44.126315Z","shell.execute_reply":"2024-08-20T13:07:44.956688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Train Model -------------------------------------------------------------------------------------------------\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\n\nbest_model = None\nbest_acc = 0\n\nfor epoch in range(NUM_EPOCHS):\n    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n    val_loss, val_acc = evaluate(model, val_loader, criterion)    \n    \n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    \n    if val_acc> best_acc:\n        best_acc = val_acc\n        best_model = copy.deepcopy(model)\n        \n    \n    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, '\n          f'Train Loss: {train_loss:.4f}, Train ACC: {train_acc:.4f}, '\n          f'Val Loss: {val_loss:.4f}, Val ACC: {val_acc:.4f}')\n    \nlast_model = copy.deepcopy(model)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:37.687133Z","iopub.execute_input":"2024-08-20T13:09:37.687496Z","iopub.status.idle":"2024-08-20T13:15:26.206098Z","shell.execute_reply.started":"2024-08-20T13:09:37.687465Z","shell.execute_reply":"2024-08-20T13:15:26.204997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Plot ACC and Loss --------------------------------------------------------------------------------------------\nepochs = range(1, NUM_EPOCHS + 1)\n\nplt.figure(figsize=(14, 5))\n\n# Plot training & validation loss\nplt.subplot(1, 2, 1)\nplt.plot(epochs, train_losses, 'bo-', label='Train Loss')\nplt.plot(epochs, val_losses, 'ro-', label='Val Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Plot training & validation accuracy\nplt.subplot(1, 2, 2)\nplt.plot(epochs, train_accuracies, 'bo-', label='Train Accuracy')\nplt.plot(epochs, val_accuracies, 'ro-', label='Val Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:35:38.123534Z","iopub.execute_input":"2024-08-20T13:35:38.124444Z","iopub.status.idle":"2024-08-20T13:35:38.665819Z","shell.execute_reply.started":"2024-08-20T13:35:38.124406Z","shell.execute_reply":"2024-08-20T13:35:38.664926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #--Evaluate Model On Test Data ---------------------------------------------------------------------------------\ntest_loss, test_acc = evaluate(best_model, test_loader, criterion)\nprint(f'Final Test Accuracy: {test_acc:.4f}')\n# #----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:35:41.727794Z","iopub.execute_input":"2024-08-20T13:35:41.728125Z","iopub.status.idle":"2024-08-20T13:35:46.440232Z","shell.execute_reply.started":"2024-08-20T13:35:41.728100Z","shell.execute_reply":"2024-08-20T13:35:46.439038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Compare Last Model and Best Model ----------------------------------------------------------------------------\n\n#-- last model --\ntrain_loss, train_acc = evaluate(last_model, train_loader, criterion)   \nval_loss, val_acc = evaluate(last_model, val_loader, criterion)   \ntest_loss, test_acc = evaluate(last_model, test_loader, criterion)\n\nprint('Last Weights:\\n'\n         f'Train Loss: {train_loss: .4f} - Train ACC: {train_acc: .4f}\\n'\n         f'Val Loss: {val_loss: .4f} - Val ACC: {val_acc: .4f}\\n'\n         f'Test Loss: {test_loss: .4f} - Test ACC: {test_loss: .4f}')\n\n#-- best model --\ntrain_loss, train_acc = evaluate(best_model, train_loader, criterion)   \nval_loss, val_acc = evaluate(best_model, val_loader, criterion)   \ntest_loss, test_acc = evaluate(best_model, test_loader, criterion)\n\nprint('Best Weights:\\n'\n         f'Train Loss: {train_loss: .4f} - Train ACC: {train_acc: .4f}\\n'\n         f'Val Loss: {val_loss: .4f} - Val ACC: {val_acc: .4f}\\n'\n         f'Test Loss: {test_loss: .4f} - Test ACC: {test_acc: .4f}')\n#----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:35:53.158486Z","iopub.execute_input":"2024-08-20T13:35:53.159187Z","iopub.status.idle":"2024-08-20T13:37:12.147065Z","shell.execute_reply.started":"2024-08-20T13:35:53.159152Z","shell.execute_reply":"2024-08-20T13:37:12.145916Z"},"trusted":true},"execution_count":null,"outputs":[]}]}